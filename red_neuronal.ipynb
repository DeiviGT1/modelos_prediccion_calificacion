{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rutas import data_clean\n",
    "maestro = data_clean()\n",
    "maestro = maestro[(maestro[\"min\"].apply(lambda x: x[:4])==\"2022\")|(maestro[\"min\"].apply(lambda x: x[:4])==\"2021\")|(maestro[\"min\"].apply(lambda x: x[:4])==\"2019\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "y = np.array(maestro[\"calif\"])\n",
    "X = maestro.copy()\n",
    "X.drop([\"calificacion\", \"calif\"], axis=1, inplace=True)\n",
    "\n",
    "X = X[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\", \"BASE TELA\"]]\n",
    "\n",
    "categorical_columns = maestro.select_dtypes(include='object').columns\n",
    "df_copy = maestro.copy()\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\", \"BASE TELA\"]]\n",
    "target = df_copy['calif']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Regresion lineal multivariada</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_criterios = {\"HOMBRE\":\n",
    "    {\"BUZO\":[\"COLOR\", \"ESTIICA\", \"TIPO\"], #TIPO PULLOVER - HOODIE\n",
    "    \"CAMISA\": [\"ESTETICA\", \"FIT\", \"COLOR\"],\n",
    "    \"CAMISETA\":[\"COLOR\", \"ESTETICA\", \"FIT\", \"TIPO\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CHAQUETA\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"JEAN\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"JOGGER\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"SHORTS\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"SHORTS PLANO\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"PANTALON\": [\"COLOR\"],\n",
    "    \"POLO\": [\"COLOR\", \"TEJIDO\", \"PUNTO CORAZON\"],\n",
    "    \"TANK\": [\"COLOR\", \"ESTETICA\", \"TIPO\"] #TIPO CHOMPA\n",
    "    },\n",
    "    \"MUJER\":{\"BUZO\":[\"COLOR\", \"ESTIICA\", \"TIPO\", \"LARGO\", \"BASE TELA\", \"SILUETA\"], #TIPO PULLOVER - HOODIE ## VALIDAR SI TENEMOS SOLUETA\n",
    "    \"CAMISA\": [\"ESTETICA\", \"TIPO\", \"COLOR\", \"LARGO\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CAMISETA\":[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CHAQUETA\": [\"COLOR\", \"ESTETICA\", \"TIPO\", \"LARGO\", \"BASE TELA\", \"SILUETA\"],\n",
    "    \"FALDA\": [\"ESTETICA\", \"BASE TELA\", \"LARGO\"],\n",
    "    \"HAREM\" : [\"SILUETA\", \"MOLDE\", \"COLOR\", \"ESTETICA\", \"BASE TELA\"],\n",
    "    \"JEAN\": [\"COLOR\", \"ESTETICA\", \"TIPO\", \"TIRO\"], #TIRO EN LA SUBCATEGORIA\n",
    "    \"JOGGER\": [\"COLOR\", \"ESTETICA\", \"SILUETA\", \"BASE TELA\", \"TIPO\"],\n",
    "    \"PANTALON\": [\"COLOR\", \"ESTETICA\", \"TIRO\", \"TIPO\"], #TIRO EN LA SUBCATEGORIA\n",
    "    \"R DEPORTIVA\": [\"COLOR\", \"ESTETICA\", \"BASE TELA\", \"SILUETA\"],\n",
    "    \"SHORTS\": [\"COLOR\", \"ESTETICA\", \"SILUETA\", \"BASE TELA\"],\n",
    "    \"SHORTS DENIM\": [\"COLOR\", \"ESTETICA\", \"BASE TELA\", \"TIRO\"],\n",
    "    \"TOP\": [\"COLOR\", \"LARGO\", \"SILUETA\", \"ESTETICA\", \"TIPO\"],\n",
    "    \"TOP ML\": [\"COLOR\", \"LARGO\", \"SILUETA\", \"ESTETICA\", \"TIPO\"],\n",
    "    \"VESTIDO\": [\"BASE TELA\", \"SILUETA\", \"LARGO\", \"ESTETICA\", \"COLOR\", \"TIPO\"], \n",
    "    \"VESTIDO DE BAÑO\": [\"COLOR\", \"ESTETICA\", \"MOLDE\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\">Modelo</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 1.5 \n",
      "mse tres: 1.73 \n",
      "El R2 es -0.07744033056851274\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    try:\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size = 0.7)\n",
    "        pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\n",
    "                        \"column_transformer\",\n",
    "                        make_column_transformer(\n",
    "                            (\n",
    "                                OneHotEncoder(),\n",
    "                                make_column_selector(dtype_include=object)\n",
    "                            ), \n",
    "                            remainder = \"passthrough\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"selectKBest\",\n",
    "                        SelectKBest(score_func=f_regression),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"linearRegression\",\n",
    "                        LinearRegression(),\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        param_grid = {\n",
    "                \"selectKBest__k\": range(1, len(X.columns)),\n",
    "            }\n",
    "        gridSearchCV = GridSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                refit=True,\n",
    "                return_train_score=False,\n",
    "            )\n",
    "        gridSearchCV.fit(X_train, y_train)\n",
    "        y_train_pred = gridSearchCV.predict(X_train)\n",
    "        y_test_pred = gridSearchCV.predict(X_test)\n",
    "        mse_train = mean_squared_error(\n",
    "            y_train_pred,\n",
    "            y_train,\n",
    "        ).round(2)\n",
    "        mse_test = mean_squared_error(\n",
    "            y_test_pred,\n",
    "            y_test,\n",
    "        ).round(2)\n",
    "\n",
    "        r_2 = r2_score(y_pred = y_test_pred, y_true = y_test)\n",
    "\n",
    "        print(f\"mse train: {mse_train} \\nmse tres: {mse_test} \\nEl R2 es {r_2}\")\n",
    "        break\n",
    "    except: continue \n",
    "print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Red Neuronal TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Softmax\n",
    "\n",
    "\n",
    "y = np.array(maestro[\"calif\"])\n",
    "X = maestro.copy()\n",
    "X.drop([\"calificacion\", \"calif\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X = X[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "X = X.to_numpy()\n",
    "\n",
    "training_data = make_column_transformer(\n",
    "                            (\n",
    "                                OneHotEncoder(),\n",
    "                                make_column_selector(dtype_include=object)\n",
    "                            ), \n",
    "                            remainder = \"passthrough\"\n",
    "                        )\n",
    "training_data = np.array(training_data)\n",
    "target_data = y\n",
    "\n",
    "# Seleccionar las columnas del dataframe que son categóricas\n",
    "categorical_columns = maestro.select_dtypes(include='object').columns\n",
    "\n",
    "# Crear una copia del dataframe para evitar modificar el original\n",
    "df_copy = maestro.copy()\n",
    "\n",
    "# Crear una instancia de LabelEncoder para cada columna categórica\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Aplicar el LabelEncoder a cada columna categórica del dataframe\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "\n",
    "# Seleccionar las columnas del dataframe que se utilizarán como características\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "\n",
    "# Seleccionar la columna del dataframe que se utilizará como objetivo\n",
    "target = df_copy['calif']\n",
    "\n",
    "# Crear un modelo de redes neuronales con Keras\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir una capa de entrada con la misma cantidad de neuronas que de características\n",
    "model.add(Dense(features.shape[1], input_dim=features.shape[1], activation='relu'))\n",
    "\n",
    "# Añadir una capa oculta con 16 neuronas\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Añadir una capa de salida con una sola neurona\n",
    "\n",
    "model.add(Dense(5, activation='Softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=CategoricalAccuracy())\n",
    "history = model.fit(features, target, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(30)\n",
    "f.set_figheight(9)\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Red Neuronal Sklearn</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.32142857142857145 \n",
      "El score en el test fue:  0.2755102040816326\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\", early_stopping=True,\n",
    "                    learning_rate=\"adaptive\", hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.6275510204081632 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.25510204081632654 \n",
      "El score en el test fue:  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.6836734693877551 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(50000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.3431542461005199 \n",
      "El score en el test fue:  0.2912280701754386\n"
     ]
    }
   ],
   "source": [
    "## Por el momento este es el mejor\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.43116883116883115 \n",
      "El score en el test fue:  0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.5714285714285714 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-50, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.29591836734693877\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(30000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.30612244897959184 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-50, activation=\"tanh\", early_stopping=True, validation_fraction= 0.001,\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.30612244897959184 \n",
      "El score en el test fue:  0.2755102040816326\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"tanh\", early_stopping=True, validation_fraction= 0.001,\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(30000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.29591836734693877 \n",
      "El score en el test fue:  0.3469387755102041\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(3000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Kmeans</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = maestro.copy()\n",
    "df_copy = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\", \"calif\"]]\n",
    "categorical_columns = df_copy.select_dtypes(include='object').columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "features = preprocessing.StandardScaler().fit_transform(features)\n",
    "target = df_copy[\"calif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-521.3988842277219"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(features)\n",
    "y_pred = kmeans.predict(features)\n",
    "kmeans.score(features, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1011.5112867810037"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(features)\n",
    "y_pred = kmeans.predict(features)\n",
    "kmeans.score(features, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Random forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3131868131868132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2807017543859649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Regresión logistica</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32280701754385965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35714285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Hierechical clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15934065934065933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14136125654450263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14385964912280702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Arbol de desicion</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29292929292929293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27017543859649124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">GaussianNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34615384615384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4052631578947368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30526315789473685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">SVM (máquinas de vectores de soporte)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32460732984293195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38421052631578945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3017543859649123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Gaussian Mixture Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1717171717171717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09340659340659341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23859649122807017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Perceptron</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16842105263157894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38421052631578945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34065934065934067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
