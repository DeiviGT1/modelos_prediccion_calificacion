{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-868775ce4627>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrutas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmaestro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jgonzalezt\\red_neuronal\\rutas.py\u001b[0m in \u001b[0;36mdata_clean\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mdf_despacho\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdespacho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mmaestro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaestro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_despacho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Item\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Item\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaestro\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   8193\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8195\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   8196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8197\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Item'"
     ]
    }
   ],
   "source": [
    "from rutas import data_clean\n",
    "maestro = data_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = np.array(maestro[\"calif\"])\n",
    "X = maestro.copy()\n",
    "X.drop([\"calificacion\", \"calif\"], axis=1, inplace=True)\n",
    "\n",
    "X = X[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "\n",
    "categorical_columns = maestro.select_dtypes(include='object').columns\n",
    "df_copy = maestro.copy()\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "target = df_copy['calif']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Regresion lineal multivariada</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_criterios = {\"HOMBRE\":\n",
    "    {\"BUZO\":[\"COLOR\", \"ESTIICA\", \"TIPO\"], #TIPO PULLOVER - HOODIE\n",
    "    \"CAMISA\": [\"ESTETICA\", \"FIT\", \"COLOR\"],\n",
    "    \"CAMISETA\":[\"COLOR\", \"ESTETICA\", \"FIT\", \"TIPO\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CHAQUETA\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"JEAN\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"JOGGER\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"SHORTS\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"SHORTS PLANO\": [\"COLOR\", \"ESTETICA\"],\n",
    "    \"PANTALON\": [\"COLOR\"],\n",
    "    \"POLO\": [\"COLOR\", \"TEJIDO\", \"PUNTO CORAZON\"],\n",
    "    \"TANK\": [\"COLOR\", \"ESTETICA\", \"TIPO\"] #TIPO CHOMPA\n",
    "    },\n",
    "    \"MUJER\":{\"BUZO\":[\"COLOR\", \"ESTIICA\", \"TIPO\", \"LARGO\", \"BASE TELA\", \"SILUETA\"], #TIPO PULLOVER - HOODIE ## VALIDAR SI TENEMOS SOLUETA\n",
    "    \"CAMISA\": [\"ESTETICA\", \"TIPO\", \"COLOR\", \"LARGO\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CAMISETA\":[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"], #TIPO MANGA CORGA - MANGA LARGA\n",
    "    \"CHAQUETA\": [\"COLOR\", \"ESTETICA\", \"TIPO\", \"LARGO\", \"BASE TELA\", \"SILUETA\"],\n",
    "    \"FALDA\": [\"ESTETICA\", \"BASE TELA\", \"LARGO\"],\n",
    "    \"HAREM\" : [\"SILUETA\", \"MOLDE\", \"COLOR\", \"ESTETICA\", \"BASE TELA\"],\n",
    "    \"JEAN\": [\"COLOR\", \"ESTETICA\", \"TIPO\", \"TIRO\"], #TIRO EN LA SUBCATEGORIA\n",
    "    \"JOGGER\": [\"COLOR\", \"ESTETICA\", \"SILUETA\", \"BASE TELA\", \"TIPO\"],\n",
    "    \"PANTALON\": [\"COLOR\", \"ESTETICA\", \"TIRO\", \"TIPO\"], #TIRO EN LA SUBCATEGORIA\n",
    "    \"R DEPORTIVA\": [\"COLOR\", \"ESTETICA\", \"BASE TELA\", \"SILUETA\"],\n",
    "    \"SHORTS\": [\"COLOR\", \"ESTETICA\", \"SILUETA\", \"BASE TELA\"],\n",
    "    \"SHORTS DENIM\": [\"COLOR\", \"ESTETICA\", \"BASE TELA\", \"TIRO\"],\n",
    "    \"TOP\": [\"COLOR\", \"LARGO\", \"SILUETA\", \"ESTETICA\", \"TIPO\"],\n",
    "    \"TOP ML\": [\"COLOR\", \"LARGO\", \"SILUETA\", \"ESTETICA\", \"TIPO\"],\n",
    "    \"VESTIDO\": [\"BASE TELA\", \"SILUETA\", \"LARGO\", \"ESTETICA\", \"COLOR\", \"TIPO\"], \n",
    "    \"VESTIDO DE BAÑO\": [\"COLOR\", \"ESTETICA\", \"MOLDE\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(maestro[\"calif\"])\n",
    "X = maestro.copy()\n",
    "X.drop([\"calificacion\", \"calif\"], axis=1, inplace=True)\n",
    "\n",
    "X = X[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\">Modelo</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse train: 1.5 \n",
      "mse tres: 1.73 \n",
      "El R2 es -0.07744033056851274\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size = 0.7)\n",
    "    \n",
    "for i in range(1000):\n",
    "    try:\n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size = 0.7)\n",
    "        pipeline = Pipeline(\n",
    "                steps=[\n",
    "                    (\n",
    "                        \"column_transformer\",\n",
    "                        make_column_transformer(\n",
    "                            (\n",
    "                                OneHotEncoder(),\n",
    "                                make_column_selector(dtype_include=object)\n",
    "                            ), \n",
    "                            remainder = \"passthrough\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"selectKBest\",\n",
    "                        SelectKBest(score_func=f_regression),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"linearRegression\",\n",
    "                        LinearRegression(),\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        param_grid = {\n",
    "                \"selectKBest__k\": range(1, len(X.columns)),\n",
    "            }\n",
    "        gridSearchCV = GridSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_grid=param_grid,\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "                refit=True,\n",
    "                return_train_score=False,\n",
    "            )\n",
    "        gridSearchCV.fit(X_train, y_train)\n",
    "        y_train_pred = gridSearchCV.predict(X_train)\n",
    "        y_test_pred = gridSearchCV.predict(X_test)\n",
    "        mse_train = mean_squared_error(\n",
    "            y_train_pred,\n",
    "            y_train,\n",
    "        ).round(2)\n",
    "        mse_test = mean_squared_error(\n",
    "            y_test_pred,\n",
    "            y_test,\n",
    "        ).round(2)\n",
    "\n",
    "        r_2 = r2_score(y_pred = y_test_pred, y_true = y_test)\n",
    "\n",
    "        print(f\"mse train: {mse_train} \\nmse tres: {mse_test} \\nEl R2 es {r_2}\")\n",
    "        break\n",
    "    except: continue \n",
    "print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Red Neuronal TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Softmax\n",
    "from keras.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "y = np.array(maestro[\"calif\"])\n",
    "X = maestro.copy()\n",
    "X.drop([\"calificacion\", \"calif\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X = X[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "X = X.to_numpy()\n",
    "\n",
    "training_data = make_column_transformer(\n",
    "                            (\n",
    "                                OneHotEncoder(),\n",
    "                                make_column_selector(dtype_include=object)\n",
    "                            ), \n",
    "                            remainder = \"passthrough\"\n",
    "                        )\n",
    "training_data = np.array(training_data)\n",
    "target_data = y\n",
    "\n",
    "# Seleccionar las columnas del dataframe que son categóricas\n",
    "categorical_columns = maestro.select_dtypes(include='object').columns\n",
    "\n",
    "# Crear una copia del dataframe para evitar modificar el original\n",
    "df_copy = maestro.copy()\n",
    "\n",
    "# Crear una instancia de LabelEncoder para cada columna categórica\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Aplicar el LabelEncoder a cada columna categórica del dataframe\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "\n",
    "# Seleccionar las columnas del dataframe que se utilizarán como características\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "\n",
    "# Seleccionar la columna del dataframe que se utilizará como objetivo\n",
    "target = df_copy['calif']\n",
    "\n",
    "# Crear un modelo de redes neuronales con Keras\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir una capa de entrada con la misma cantidad de neuronas que de características\n",
    "model.add(Dense(features.shape[1], input_dim=features.shape[1], activation='relu'))\n",
    "\n",
    "# Añadir una capa oculta con 16 neuronas\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Añadir una capa de salida con una sola neurona\n",
    "\n",
    "model.add(Dense(5, activation='Softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=CategoricalAccuracy())\n",
    "history = model.fit(features, target, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(30)\n",
    "f.set_figheight(9)\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Red Neuronal Sklearn</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = maestro.select_dtypes(include='object').columns\n",
    "\n",
    "# Crear una copia del dataframe para evitar modificar el original\n",
    "df_copy = maestro.copy()\n",
    "\n",
    "# Crear una instancia de LabelEncoder para cada columna categórica\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Aplicar el LabelEncoder a cada columna categórica del dataframe\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "\n",
    "# Seleccionar las columnas del dataframe que se utilizarán como características\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "\n",
    "# Seleccionar la columna del dataframe que se utilizará como objetivo\n",
    "target = df_copy['calif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.32142857142857145 \n",
      "El score en el test fue:  0.2755102040816326\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\", early_stopping=True,\n",
    "                    learning_rate=\"adaptive\", hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.6275510204081632 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.25510204081632654 \n",
      "El score en el test fue:  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.6836734693877551 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(50000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.34183673469387754 \n",
      "El score en el test fue:  0.3163265306122449\n"
     ]
    }
   ],
   "source": [
    "## Por el momento este es el mejor\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.43116883116883115 \n",
      "El score en el test fue:  0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.3535528596187175 \n",
      "El score en el test fue:  0.30526315789473685\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.5714285714285714 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-50, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.29591836734693877\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(30000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(3000, 200), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.30612244897959184 \n",
      "El score en el test fue:  0.25510204081632654\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-50, activation=\"tanh\", early_stopping=True, validation_fraction= 0.001,\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.30612244897959184 \n",
      "El score en el test fue:  0.2755102040816326\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-50, activation=\"tanh\", early_stopping=True, validation_fraction= 0.001,\n",
    "                    hidden_layer_sizes=(30, 20000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.336734693877551 \n",
      "El score en el test fue:  0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', activation=\"relu\", learning_rate= \"adaptive\",\n",
    "                    hidden_layer_sizes=(30000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El score en el training fue:  0.29591836734693877 \n",
      "El score en el test fue:  0.3469387755102041\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, activation=\"relu\",\n",
    "                    hidden_layer_sizes=(3000, 2000), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"El score en el training fue: \", clf.score(X_train, y_train), \"\\nEl score en el test fue: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Kmeans</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing \n",
    "\n",
    "df_copy = maestro.copy()\n",
    "df_copy = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\", \"calif\"]]\n",
    "categorical_columns = df_copy.select_dtypes(include='object').columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = label_encoders[col].fit_transform(df_copy[col])\n",
    "features = df_copy[[\"COLOR\", \"ESTETICA\", \"LARGO\", \"SILUETA\"]]\n",
    "features = preprocessing.StandardScaler().fit_transform(features)\n",
    "target = df_copy[\"calif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-521.3988842277219"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(features)\n",
    "y_pred = kmeans.predict(features)\n",
    "kmeans.score(features, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1011.5112867810037"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(features)\n",
    "y_pred = kmeans.predict(features)\n",
    "kmeans.score(features, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Random forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23469387755102042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29473684210526313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Regresión logistica</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39473684210526316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3192982456140351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Hierechical clustering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10204081632653061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08421052631578947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11228070175438597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "cluster = AgglomerativeClustering(n_clusters=5)\n",
    "y_pred = cluster.fit_predict(X_train)\n",
    "y_pred = cluster.fit_predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Arbol de desicion</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20408163265306123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2771929824561403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">GaussianNB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3163265306122449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4052631578947368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982456140350877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">SVM (máquinas de vectores de soporte)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2755102040816326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38421052631578945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3017543859649123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Gaussian Mixture Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11224489795918367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15263157894736842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "clf = GaussianMixture(n_components=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Perceptron</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17346938775510204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38421052631578945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24561403508771928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLOR</th>\n",
       "      <th>ESTETICA</th>\n",
       "      <th>LARGO</th>\n",
       "      <th>SILUETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63716</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48000</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56366</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56352</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38589</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62481</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52859</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32777</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33477</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       COLOR  ESTETICA  LARGO  SILUETA\n",
       "Item                                  \n",
       "63716     14         7      2        1\n",
       "48000      4         7      2        1\n",
       "56366     14        11      0        1\n",
       "56352     14        11      2        2\n",
       "38589      4         7      2        2\n",
       "...      ...       ...    ...      ...\n",
       "36111     22        11      2        1\n",
       "62481      1        12      0        2\n",
       "52859     19         7      2        2\n",
       "32777     22         3      2        2\n",
       "33477     13        11      2        2\n",
       "\n",
       "[862 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
